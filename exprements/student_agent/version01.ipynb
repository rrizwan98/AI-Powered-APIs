{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from utils import read_all_students, read_students, create_students, update_students, delete_students\n",
    "from db import Session, engine, Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY1\")\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_all_students [Student(name='talal', age=40, id=2, grade='A'), Student(name='Raza', age=26, id=1, grade='B'), Student(name='Zia', age=24, id=3, grade='A')]\n"
     ]
    }
   ],
   "source": [
    "print(\"read_all_students\",read_all_students())             #pass the image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# _ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_instructions = \"\"\"This GPT acts as a student database, providing information and managing student records. It should offer details like student names, enrollment status, course registrations, grades, and any other relevant academic information. It will prioritize data accuracy and confidentiality, ensuring sensitive information is handled appropriately. The GPT should ask for clarifications if needed and personalize responses to fit the user's inquiry. It will avoid giving out personal data without verification of the user's authority to access such information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_all_students_data\",\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_student_by_id\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"student_id\": {\"type\": \"integer\"},\n",
    "                },\n",
    "                \"required\": [\"student_id\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map available functions\n",
    "available_function = {\n",
    "    \"read_all_students_data\": read_all_students,\n",
    "    \"read_student_by_id\": read_students\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletionMessage, ChatCompletion\n",
    "# from openai.types.chat.chat_completion import ChatCompletionMessageParam, ChatCompletionMessageParam\n",
    "\n",
    "def run_conversation(main_request: str)->str:\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": main_request}]\n",
    "    tools = tool\n",
    "    # First Request\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message: ChatCompletionMessage = response.choices[0].message\n",
    "    display(\"* First Response: \", dict(response_message))\n",
    "\n",
    "    tool_calls = response_message.tool_calls\n",
    "    display(\"* First Reponse Tool Calls: \", list(tool_calls))\n",
    "\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = available_function  # only one function in this example, but you can have multiple\n",
    "        \n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        \n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            print('function_name', function_name)\n",
    "            print('function_arguments', function_args)\n",
    "\n",
    "            if function_name in available_functions:\n",
    "                function_to_call = available_functions[function_name]\n",
    "                output = function_to_call(**function_args)\n",
    "\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_args,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        display(\"* Second Request Messages: \", list(messages))\n",
    "        second_response: ChatCompletion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(\"* Second Response: \", dict(second_response))\n",
    "        return second_response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* First Response: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_3MR4s2Rm0c2S7YbGQdOy4VdT', function=Function(arguments='{}', name='read_all_students_data'), type='function')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'* First Reponse Tool Calls: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_3MR4s2Rm0c2S7YbGQdOy4VdT', function=Function(arguments='{}', name='read_all_students_data'), type='function')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_name read_all_students_data\n",
      "function_arguments {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* Second Request Messages: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'list the all student in db'},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3MR4s2Rm0c2S7YbGQdOy4VdT', function=Function(arguments='{}', name='read_all_students_data'), type='function')]),\n",
       " {'tool_call_id': 'call_3MR4s2Rm0c2S7YbGQdOy4VdT',\n",
       "  'role': 'tool',\n",
       "  'name': 'read_all_students_data',\n",
       "  'content': {}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Second Response:  {'id': 'chatcmpl-943GSPZVo8m34lJvdq2YZvNWbTBTV', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I don't have access to the database to retrieve the list of all students.\", role='assistant', function_call=None, tool_calls=None))], 'created': 1710752888, 'model': 'gpt-3.5-turbo-1106', 'object': 'chat.completion', 'system_fingerprint': 'fp_4aaaf0dc94', 'usage': CompletionUsage(completion_tokens=21, prompt_tokens=35, total_tokens=56)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to the database to retrieve the list of all students.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_conversation(\"list the all student in db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
