{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import folium\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import webbrowser\n",
    "from folium import plugins\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "from utils import read_all_students, read_students, create_students, update_students, delete_students\n",
    "from db import Session, engine, Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TEXON WARE\\AppData\\Local\\Programs\\Python\\lib\\site-packages\\sqlmodel\\orm\\session.py:60: SAWarning: Class SelectOfScalar will not make use of SQL compilation caching as it does not set the 'inherit_cache' attribute to ``True``.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this object can make use of the cache key generated by the superclass.  Alternatively, this attribute may be set to False which will disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)\n",
      "  results = super().execute(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_all_students [Student(name='talal', age=40, id=2, grade='A'), Student(name='Raza', age=26, id=1, grade='B'), Student(name='Zia', age=24, id=3, grade='A')]\n"
     ]
    }
   ],
   "source": [
    "print(\"read_all_students\",read_all_students())             #pass the image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# _ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map available functions\n",
    "available_functions = {\n",
    "    \"read_all_students_data\": read_all_students,\n",
    "    \"read_student_by_id\": read_students,\n",
    "    # \"create_new_students\": create_students,\n",
    "    # \"update_student\": update_students,\n",
    "    \"delete_student\": delete_students\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_instructions = \"\"\"This GPT acts as a student database, providing information and managing student records. It should offer details like student names, enrollment status, course registrations, grades, and any other relevant academic information. It will prioritize data accuracy and confidentiality, ensuring sensitive information is handled appropriately. The GPT should ask for clarifications if needed and personalize responses to fit the user's inquiry. It will avoid giving out personal data without verification of the user's authority to access such information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_all_students_data\",\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_student_by_id\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"student_id\": {\"type\": \"integer\"},\n",
    "                },\n",
    "                \"required\": [\"student_id\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\n",
    "    #         \"name\": \"create_new_students\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"student\": ({\"type\": Student})\n",
    "    #             },\n",
    "    #             \"required\": [\"student\"],\n",
    "    #         }\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"delete_student\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"student_id\": {\"type\": \"integer\"},\n",
    "                },\n",
    "                \"required\": [\"student_id\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_to_dict(student):\n",
    "    # Assuming 'student' has attributes you want to serialize.\n",
    "    # Adjust the attributes as necessary.\n",
    "    return {\n",
    "        \"id\": student.id,\n",
    "        \"name\": student.name,\n",
    "        \"age\": student.age,\n",
    "        \"grade\": student.grade\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to Manage All Open API Assistant Calls and Functions\n",
    "from openai.types.beta.threads import Run, ThreadMessage\n",
    "from openai.types.beta.thread import Thread\n",
    "from openai.types.beta.assistant_create_params import Tool\n",
    "\n",
    "import time\n",
    "\n",
    "class StudentAssistantManager:\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo-1106\"):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.assistant = None\n",
    "        self.thread = None\n",
    "        self.run = None\n",
    "\n",
    "    def create_assistant(self, name: str, instructions: str, tools: list[Tool]) -> None:\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            name=name,\n",
    "            instructions=instructions,\n",
    "            tools=tools,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "    def create_thread(self) -> Thread:\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        return self.thread\n",
    "\n",
    "    def add_message_to_thread(self, role: str, content: str) -> None:\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=self.thread.id,\n",
    "            role=role,\n",
    "            content=content\n",
    "        )\n",
    "\n",
    "    def run_assistant(self, instructions: str) -> Run:\n",
    "        self.run = self.client.beta.threads.runs.create(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            instructions=instructions\n",
    "        )\n",
    "        return self.run\n",
    "\n",
    "    def wait_for_completion(self, run: Run, thread: Thread) -> Run:\n",
    "\n",
    "        while run.status in [\"in_progress\", \"queued\"]:\n",
    "            run_status = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=self.run.id\n",
    "            )\n",
    "            print(f\"Run is {run.status}. Waiting...\")\n",
    "            time.sleep(3)  # Wait for 3 seconds before checking again\n",
    "\n",
    "            if run_status.status == 'completed':\n",
    "                processed_response = self.process_messages()\n",
    "                return processed_response\n",
    "                # break\n",
    "            elif run_status.status == 'requires_action':\n",
    "                print(\"Function Calling ...\")\n",
    "                self.call_required_functions(run_status.required_action.submit_tool_outputs.model_dump())\n",
    "            elif run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Waiting for the Assistant to process...: {run.status}\")\n",
    "\n",
    "    def process_messages(self) -> list[ThreadMessage]:\n",
    "        messages: list[ThreadMessage] = self.client.beta.threads.messages.list(thread_id=self.thread.id)\n",
    "        return messages\n",
    "\n",
    "    def call_required_functions(self, required_actions: dict):\n",
    "        tool_outputs = []\n",
    "\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            function_name = action['function']['name']\n",
    "            arguments = json.loads(action['function']['arguments'])\n",
    "            print('function_name', function_name)\n",
    "            print('function_arguments', arguments)\n",
    "\n",
    "            if function_name in available_functions:\n",
    "                function_to_call = available_functions[function_name]\n",
    "                output = function_to_call(**arguments)\n",
    "\n",
    "                # Check if output is an instance of Student and convert to dict if so\n",
    "                if isinstance(output, Student):\n",
    "                    output = student_to_dict(output)\n",
    "                elif isinstance(output, list) and all(isinstance(item, Student) for item in output):\n",
    "                    output = [student_to_dict(student) for student in output]\n",
    "\n",
    "                # Ensure output is serializable to JSON\n",
    "                output = json.dumps(output, default=str)  # Use default=str to handle any other non-serializable types\n",
    "\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": action['id'],\n",
    "                    \"output\": output,  # This is now ensured to be a string\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown function: {function_name}\")\n",
    "\n",
    "        print(\"Submitting outputs back to the Assistant...\")\n",
    "        self.client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=self.thread.id,\n",
    "            run_id=self.run.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Messages and Plot Images in Financial Analysis If ANY\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def download_and_save_image(file_id: str, save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads an image from OpenAI using its file ID and saves it to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - file_id (str): The ID of the file to download.\n",
    "    - save_path (str): The path where the image will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Construct the URL to download the image\n",
    "    download_url = f\"https://api.openai.com/v1/files/{file_id}/content\"\n",
    "\n",
    "    # Perform the HTTP GET request to download the image\n",
    "    response = requests.get(download_url, headers={\"Authorization\": f'Bearer {os.getenv(\"OPENAI_API_KEY\")}'})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write the image to the specified file\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Image downloaded and saved to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image: HTTP Status Code {response.status_code}\")\n",
    "\n",
    "\n",
    "def pretty_print(messages: list[ThreadMessage]) -> None:\n",
    "    print(\"# Messages\")\n",
    "    for message in messages.data:\n",
    "        role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "        # Check the type of message content and handle accordingly\n",
    "        for content in message.content:\n",
    "            if content.type == \"text\":\n",
    "                message_content = content.text.value\n",
    "                print(f\"{role_label}: {message_content}\\n\")\n",
    "                print()\n",
    "            elif content.type == \"image_file\":\n",
    "                # Handle image file content, e.g., print the file ID or download the image\n",
    "                image_file_id = content.image_file.file_id\n",
    "                print(f\"{role_label}: Image file ID: {image_file_id}\")\n",
    "                # Define a path to save the image\n",
    "                image_save_path = f\"image_{image_file_id}.png\"\n",
    "                # Download and save the image\n",
    "                # print(f\"{role_label}: Image file ID: {image_file_id}\")\n",
    "                download_and_save_image(image_file_id, image_save_path)\n",
    "\n",
    "                # Display the image within Jupyter Notebook\n",
    "                display(Image(filename=image_save_path))\n",
    "\n",
    "                #   # Open and display the image\n",
    "                # try:\n",
    "                #     img = Image.open(image_save_path)\n",
    "                #     img.show()\n",
    "                # except IOError:\n",
    "                #     print(\"Error in opening the image file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmp_financial_analyst(prompt: str):\n",
    "    fmp_analyst = StudentAssistantManager()\n",
    "\n",
    "    fmp_analyst.create_assistant(\n",
    "        name=\"StudentAssistant\",\n",
    "        instructions=bot_instructions,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    fmp_analyst.create_thread()\n",
    "\n",
    "    fmp_analyst.add_message_to_thread(\n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )\n",
    "\n",
    "    run = fmp_analyst.run_assistant(\n",
    "        instructions=bot_instructions\n",
    "    )\n",
    "\n",
    "    final_res = fmp_analyst.wait_for_completion(\n",
    "        run=run,\n",
    "        thread=fmp_analyst.thread\n",
    "    )\n",
    "\n",
    "    return final_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis1 = fmp_financial_analyst(\"Can you compare the financial health of Microsoft and Apple over the last years, focusing on their balance sheets and key financial ratios?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty_print(analysis1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Microsoft vs. Googles's revenue & profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name read_all_students_data\n",
      "function_arguments {}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response1 = fmp_financial_analyst(\"\"\"\n",
    "list the all student in db\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: Here are the students in the database:\n",
      "1. Name: Raza, Age: 26, Grade: B\n",
      "2. Name: Talal, Age: 40, Grade: A\n",
      "3. Name: Zia, Age: 24, Grade: A\n",
      "\n",
      "\n",
      "User: \n",
      "list the all student in db\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name read_student_by_id\n",
      "function_arguments {'student_id': 1}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response2 = fmp_financial_analyst(\"\"\"\n",
    "get the student id 1 data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The student with ID 1 is Raza. He is 26 years old and has a grade of B.\n",
      "\n",
      "\n",
      "User: \n",
      "get the student id 1 data\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name read_all_students_data\n",
      "function_arguments {}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response3 = fmp_financial_analyst(\"\"\"\n",
    "get the id of student name Raza\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The student ID of Raza is 1.\n",
      "\n",
      "\n",
      "User: \n",
      "get the id of student name Raza\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name delete_student\n",
      "function_arguments {'student_id': 1}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response4 = fmp_financial_analyst(\"\"\"\n",
    "delete the ID 1 student data from db\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The student with ID 1 has been successfully deleted from the database.\n",
      "\n",
      "\n",
      "User: \n",
      "delete the ID 1 student data from db\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name read_all_students_data\n",
      "function_arguments {}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response1 = fmp_financial_analyst(\"\"\"\n",
    "list the all student in db with id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The following students are currently in the database:\n",
      "\n",
      "1. Student ID: 2, Name: Talal, Age: 40, Grade: A\n",
      "2. Student ID: 3, Name: Zia, Age: 24, Grade: A\n",
      "\n",
      "\n",
      "User: \n",
      "list the all student in db with id\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
