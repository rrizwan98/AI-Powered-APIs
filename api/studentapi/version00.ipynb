{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import folium\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import webbrowser\n",
    "from folium import plugins\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "from utils import read_all_students, read_students, create_students, update_students, delete_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"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\"\n"
     ]
    }
   ],
   "source": [
    "encoding = 'utf-8'\n",
    "def load_configuration(file_path: str) -> dict:\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "# Load configurations\n",
    "config = load_configuration('env.yaml')\n",
    "OPENAI_API_KEY:str = config.get('OPENAI_API_KEY', '')\n",
    "print(OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_all_students [Student(grade='A', id=2, name='talal', age=40), Student(grade='B', id=1, name='Raza', age=26), Student(grade='A', id=3, name='Zia', age=24)]\n"
     ]
    }
   ],
   "source": [
    "print(\"read_all_students\",read_all_students())             #pass the image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# _ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map available functions\n",
    "available_functions = {\n",
    "    \"read_all_students_data\": read_all_students,\n",
    "    \"read_student_by_id\": read_students,\n",
    "    \"create_new_students\": create_students,\n",
    "    \"update_student\": update_students,\n",
    "    \"delete_student\": delete_students\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_instructions = \"\"\"This GPT acts as a student database, providing information and managing student records. It should offer details like student names, enrollment status, course registrations, grades, and any other relevant academic information. It will prioritize data accuracy and confidentiality, ensuring sensitive information is handled appropriately. The GPT should ask for clarifications if needed and personalize responses to fit the user's inquiry. It will avoid giving out personal data without verification of the user's authority to access such information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_all_students_data\",\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_student_by_id\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"student_id\": {\"type\": \"integer\"},\n",
    "                },\n",
    "                \"required\": [\"student_id\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_new_students\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Student\": {\"id\": \"integer\",\n",
    "                                 \"name\": \"string\",\n",
    "                                 \"age\": \"integer\",\n",
    "                                 \"grade\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"Student\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"delete_student\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"student_id\": {\"type\": \"integer\"},\n",
    "                },\n",
    "                \"required\": [\"student_id\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to Manage All Open API Assistant Calls and Functions\n",
    "from openai.types.beta.threads import Run, ThreadMessage\n",
    "from openai.types.beta.thread import Thread\n",
    "from openai.types.beta.assistant_create_params import Tool\n",
    "\n",
    "import time\n",
    "\n",
    "class AgricultureAssistantManager:\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo-1106\"):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.assistant = None\n",
    "        self.thread = None\n",
    "        self.run = None\n",
    "\n",
    "    def create_assistant(self, name: str, instructions: str, tools: list[Tool]) -> None:\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            name=name,\n",
    "            instructions=instructions,\n",
    "            tools=tools,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "    def create_thread(self) -> Thread:\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        return self.thread\n",
    "\n",
    "    def add_message_to_thread(self, role: str, content: str) -> None:\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=self.thread.id,\n",
    "            role=role,\n",
    "            content=content\n",
    "        )\n",
    "\n",
    "    def run_assistant(self, instructions: str) -> Run:\n",
    "        self.run = self.client.beta.threads.runs.create(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            instructions=instructions\n",
    "        )\n",
    "        return self.run\n",
    "\n",
    "    def wait_for_completion(self, run: Run, thread: Thread) -> Run:\n",
    "\n",
    "        while run.status in [\"in_progress\", \"queued\"]:\n",
    "            run_status = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=self.run.id\n",
    "            )\n",
    "            print(f\"Run is {run.status}. Waiting...\")\n",
    "            time.sleep(3)  # Wait for 3 seconds before checking again\n",
    "\n",
    "            if run_status.status == 'completed':\n",
    "                processed_response = self.process_messages()\n",
    "                return processed_response\n",
    "                # break\n",
    "            elif run_status.status == 'requires_action':\n",
    "                print(\"Function Calling ...\")\n",
    "                self.call_required_functions(run_status.required_action.submit_tool_outputs.model_dump())\n",
    "            elif run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Waiting for the Assistant to process...: {run.status}\")\n",
    "\n",
    "    def process_messages(self) -> list[ThreadMessage]:\n",
    "        messages: list[ThreadMessage] = self.client.beta.threads.messages.list(thread_id=self.thread.id)\n",
    "        return messages\n",
    "\n",
    "    def call_required_functions(self, required_actions: dict):\n",
    "        tool_outputs = []\n",
    "\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            function_name = action['function']['name']\n",
    "            arguments = json.loads(action['function']['arguments'])\n",
    "            print('function_name', function_name)\n",
    "            print('function_arguments', arguments)\n",
    "\n",
    "            if function_name in available_functions:\n",
    "                function_to_call = available_functions[function_name]\n",
    "                output = function_to_call(**arguments)\n",
    "\n",
    "                # Serialize output to a string if it's not already one\n",
    "                if not isinstance(output, str):\n",
    "                    output = json.dumps(output)\n",
    "\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": action['id'],\n",
    "                    \"output\": output,  # This is now ensured to be a string\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown function: {function_name}\")\n",
    "\n",
    "        print(\"Submitting outputs back to the Assistant...\")\n",
    "        self.client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=self.thread.id,\n",
    "            run_id=self.run.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Messages and Plot Images in Financial Analysis If ANY\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def download_and_save_image(file_id: str, save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads an image from OpenAI using its file ID and saves it to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - file_id (str): The ID of the file to download.\n",
    "    - save_path (str): The path where the image will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Construct the URL to download the image\n",
    "    download_url = f\"https://api.openai.com/v1/files/{file_id}/content\"\n",
    "\n",
    "    # Perform the HTTP GET request to download the image\n",
    "    response = requests.get(download_url, headers={\"Authorization\": f'Bearer {os.getenv(\"OPENAI_API_KEY\")}'})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write the image to the specified file\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Image downloaded and saved to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image: HTTP Status Code {response.status_code}\")\n",
    "\n",
    "\n",
    "def pretty_print(messages: list[ThreadMessage]) -> None:\n",
    "    print(\"# Messages\")\n",
    "    for message in messages.data:\n",
    "        role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "        # Check the type of message content and handle accordingly\n",
    "        for content in message.content:\n",
    "            if content.type == \"text\":\n",
    "                message_content = content.text.value\n",
    "                print(f\"{role_label}: {message_content}\\n\")\n",
    "                print()\n",
    "            elif content.type == \"image_file\":\n",
    "                # Handle image file content, e.g., print the file ID or download the image\n",
    "                image_file_id = content.image_file.file_id\n",
    "                print(f\"{role_label}: Image file ID: {image_file_id}\")\n",
    "                # Define a path to save the image\n",
    "                image_save_path = f\"image_{image_file_id}.png\"\n",
    "                # Download and save the image\n",
    "                # print(f\"{role_label}: Image file ID: {image_file_id}\")\n",
    "                download_and_save_image(image_file_id, image_save_path)\n",
    "\n",
    "                # Display the image within Jupyter Notebook\n",
    "                display(Image(filename=image_save_path))\n",
    "\n",
    "                #   # Open and display the image\n",
    "                # try:\n",
    "                #     img = Image.open(image_save_path)\n",
    "                #     img.show()\n",
    "                # except IOError:\n",
    "                #     print(\"Error in opening the image file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmp_financial_analyst(prompt: str):\n",
    "    fmp_analyst = AgricultureAssistantManager()\n",
    "\n",
    "    fmp_analyst.create_assistant(\n",
    "        name=\"AgricultureAssistant\",\n",
    "        instructions=bot_instructions,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    fmp_analyst.create_thread()\n",
    "\n",
    "    fmp_analyst.add_message_to_thread(\n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )\n",
    "\n",
    "    run = fmp_analyst.run_assistant(\n",
    "        instructions=bot_instructions\n",
    "    )\n",
    "\n",
    "    final_res = fmp_analyst.wait_for_completion(\n",
    "        run=run,\n",
    "        thread=fmp_analyst.thread\n",
    "    )\n",
    "\n",
    "    return final_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis1 = fmp_financial_analyst(\"Can you compare the financial health of Microsoft and Apple over the last years, focusing on their balance sheets and key financial ratios?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty_print(analysis1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Microsoft vs. Googles's revenue & profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response2 \u001b[38;5;241m=\u001b[39m \u001b[43mfmp_financial_analyst\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;43mlist the all student in db\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m, in \u001b[0;36mfmp_financial_analyst\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfmp_financial_analyst\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     fmp_analyst \u001b[38;5;241m=\u001b[39m \u001b[43mAgricultureAssistantManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     fmp_analyst\u001b[38;5;241m.\u001b[39mcreate_assistant(\n\u001b[0;32m      5\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgricultureAssistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         instructions\u001b[38;5;241m=\u001b[39mbot_instructions,\n\u001b[0;32m      7\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     fmp_analyst\u001b[38;5;241m.\u001b[39mcreate_thread()\n",
      "Cell \u001b[1;32mIn[64], line 10\u001b[0m, in \u001b[0;36mAgricultureAssistantManager.__init__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-1106\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TEXON WARE\\AppData\\Local\\Programs\\Python\\lib\\site-packages\\openai\\_client.py:98\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m     96\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "response2 = fmp_financial_analyst(\"\"\"\n",
    "list the all student in db\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The plant in the image is a succulent, specifically an Echeveria. If you have any more questions about succulents or any other plant-related queries, feel free to ask!\n",
      "\n",
      "\n",
      "User: \n",
      "which plant do you see in this image?\n",
      "\"https://dukaan.b-cdn.net/700x700/webp/730950/570a0a01-8039-4174-b518-9bf54edfe5fb/img-0348-4f923a91-eb5f-4685-9252-067786e91346.JPEG\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name get_poisonous_plant\n",
      "function_arguments {'location': 'new york park'}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response2 = fmp_financial_analyst(\"\"\"\n",
    "poisonous plant in new york park\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n",
      "Function Calling ...\n",
      "function_name get_plant_diseases\n",
      "function_arguments {'image_url': 'https://www.almanac.com/sites/default/files/image_nodes/tomato-rust.jpg'}\n",
      "Submitting outputs back to the Assistant...\n",
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response3 = fmp_financial_analyst(\"\"\"\n",
    "what is Rust plant diseases describe in 10 words\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The poisonous plant found in New York parks is Poison Ivy (Toxicodendron radicans). Exposure to Poison Ivy can cause severe skin irritation, known as contact dermatitis. Symptoms include redness, itching, swelling, and blisters. The rash can be extremely uncomfortable and can take several weeks to heal. Children are at particular risk because their skin is more sensitive and they may not be aware of the dangers of the plant.\n",
      "\n",
      "Safety Recommendations:\n",
      "1. Learn to identify Poison Ivy and other poisonous plants common in your area.\n",
      "2. Wear long sleeves, pants, and gloves when working in areas where Poison Ivy may be present.\n",
      "3. If you come into contact with Poison Ivy, wash the area thoroughly with soap and water as soon as possible.\n",
      "4. Apply a calamine lotion or hydrocortisone cream to help relieve itching and inflammation.\n",
      "\n",
      "\n",
      "User: \n",
      "poisonous plant in new york park\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: I apologize, but it seems that I encountered an issue while trying to retrieve information on Rust plant diseases. Please feel free to ask about any other plant diseases, or let me know if there's anything else I can assist you with!\n",
      "\n",
      "\n",
      "User: \n",
      "what is Rust plant diseases describe in 10 words\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued. Waiting...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued. Waiting...\n"
     ]
    }
   ],
   "source": [
    "response2 = fmp_financial_analyst(\"brif explain about financial modeling prep API explain in max 50 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: The Financial Modeling Prep API provides access to comprehensive financial data, including income statements, balance sheets, cash flow statements, key metrics, financial ratios, and growth trends. It allows analysts to retrieve, analyze, and integrate fundamental financial data for various stocks and companies.\n",
      "\n",
      "\n",
      "User: brif explain about financial modeling prep API explain in max 50 words\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ask Question reather then function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
